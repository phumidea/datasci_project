{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd04f88000c8533031533e72db95377eafe47e62948e92f30427c766512767d20f6",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "4f88000c8533031533e72db95377eafe47e62948e92f30427c766512767d20f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "source": [
    "# This is function for project1\n",
    "\n",
    "## 1) Function with white markdown is subfunction\n",
    "## 2) Function with blue markdown is aggregate function from subfunction ([You only need to use function with blue markdown])"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### show_head_text is function for read txt file and show head -n line"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_head_text(fileName, n_line):\n",
    "\n",
    "    f = open(fileName, \"r\")\n",
    "    for i in range(n_line):\n",
    "        print(f.readline())\n",
    "    f.close()"
   ]
  },
  {
   "source": [
    "### convert text file to dataframe without any edit format"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def txt_to_df(fileName):\n",
    "\n",
    "    f = open(fileName,\"r\")\n",
    "\n",
    "    ### count for determine line\n",
    "    count = 0\n",
    "\n",
    "    # metadata_df = pd.DataFrame(columns = header)\n",
    "    info_data = dict()\n",
    "    for line in f:\n",
    "        count += 1\n",
    "        tmp = line\n",
    "\n",
    "        if count < 10:\n",
    "            head = tmp[2:].split(\":\")[0]\n",
    "            data = tmp[2:].split(\":\")[1][1:-1]\n",
    "            info_data[head] = [data]\n",
    "\n",
    "        ### This line we determine that is header\n",
    "        elif count == 10:\n",
    "\n",
    "            ### We remove \"% \" at first 2 string and split each string \n",
    "            header = tmp[2:].split(\", \")\n",
    "\n",
    "            ### The last word will contains \"\\n\" so we remove it\n",
    "            header[-1] = header[-1][:-1]\n",
    "            \n",
    "            ### Create dataframe to support data will be coming after this line\n",
    "            df = pd.DataFrame(columns = header)\n",
    "\n",
    "        else:\n",
    "            data = tmp.split()\n",
    "            data_df = pd.DataFrame([data], columns = header)\n",
    "            df = df.append(data_df)\n",
    "    \n",
    "    f.close()\n",
    "    \n",
    "    df = df.reset_index().drop(columns = [\"index\"])\n",
    "    info_df = pd.DataFrame.from_dict(info_data)\n",
    "    return info_df, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "### convert any time unit with len one eg. 7 => 07"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_len2(time):\n",
    "    if len(time) == 1:\n",
    "        time = \"0\" + time\n",
    "    return time"
   ]
  },
  {
   "source": [
    "### convert all specfic headers to len 2 by use make_len2"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_make_len2(df, headers):\n",
    "\n",
    "    for header in headers:  \n",
    "        df[header] = df[header].apply(lambda x: make_len2(x))\n",
    "    return df"
   ]
  },
  {
   "source": [
    "### create datetime columns by input specific (eg. hour, month ,day, utc hour)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datetime(df, headers, string_format):\n",
    "    df[\"datestr\"] = \"\"\n",
    "    for header in headers:\n",
    "        df[\"datestr\"] += df[header]\n",
    "    df[\"datetime\"] = pd.to_datetime(df[\"datestr\"], format=string_format)\n",
    "    return df"
   ]
  },
  {
   "source": [
    "### Shift datetime to specific utc"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shiftTime(hour):\n",
    "    df[\"datetime\"] = df[\"datetime\"] + timedelta(hours=hour)\n",
    "    df[\"UTC Hour\"] = df[\"UTC Hour\"] + hour\n",
    "    return df[\"datetime\"]"
   ]
  },
  {
   "source": [
    "### Extract string datetime for pm2.5"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pm_datetime(df):\n",
    "    df[\"Year\"] = df[\"datetime_str\"].apply(lambda x: x[:4])\n",
    "    df[\"Month\"] = df[\"datetime_str\"].apply(lambda x: x[5:7])\n",
    "    df[\"Day\"] = df[\"datetime_str\"].apply(lambda x: x[8:10])\n",
    "    df[\"UTC Hour\"] = df[\"datetime_str\"].apply(lambda x: x[11:13])\n",
    "    df.drop(columns = [\"datetime_str\"], inplace = True)\n",
    "    return df"
   ]
  },
  {
   "source": [
    "### merege all function before to convert txt file to df with shift UTC"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def txt_to_df_with_shift_datetime(fileName):\n",
    "\n",
    "    info_df, df = txt_to_df(fileName)\n",
    "    header_to_numeric = [\"PM2.5\", \"PM10_mask\", \"Retrospective\"]\n",
    "    for header in header_to_numeric:\n",
    "        df[header] = pd.to_numeric(df[header])\n",
    "    df = all_make_len2(df, [\"Month\", \"Day\", \"UTC Hour\"])\n",
    "    df = create_datetime(df, [\"Year\",\"Month\",\"Day\",\"UTC Hour\"], \"%Y%m%d%H\")\n",
    "    df.drop(columns = [\"datestr\"], inplace = True)\n",
    "    df[\"datetime\"] = df[\"datetime\"] + timedelta(hours=7)\n",
    "    df[\"datetime_str\"] = df[\"datetime\"].astype(str)\n",
    "    df = extract_pm_datetime(df)\n",
    "    \n",
    "    return info_df, df"
   ]
  },
  {
   "source": [
    "### check datetime value is out of range or not"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_city_feature_unique(df, headers, city):\n",
    "    print(\"-\"*30)\n",
    "    for header in headers:\n",
    "        print(city + \" \" + header)\n",
    "        print(df[header].unique())\n",
    "        print(\"-\"*30)"
   ]
  },
  {
   "source": [
    "### Check null value all columns in dataframe"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_null_all(df):\n",
    "    null_counts = df.isnull().sum()\n",
    "    print(\"Number of null values in each column:\\n{}\".format(null_counts))"
   ]
  },
  {
   "source": [
    "### See trend in pm2.5 each year"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pm_trend_each_year(df):\n",
    "\n",
    "    df_plot1 = df[df[\"Year\"] == 2016].groupby([\"Month\"]).mean()\n",
    "    plt.plot([i for i in range(3,13)], df_plot1[\"PM2.5\"], label = \"year 2016\")\n",
    "    \n",
    "    df_plot2 = df[df[\"Year\"] == 2017].groupby([\"Month\"]).mean()\n",
    "    plt.plot([i for i in range(1,13)], df_plot2[\"PM2.5\"], label = \"year 2017\")\n",
    "\n",
    "    df_plot3 = df[df[\"Year\"] == 2018].groupby([\"Month\"]).mean()\n",
    "    plt.plot([i for i in range(1,13)], df_plot3[\"PM2.5\"], label = \"year 2018\")\n",
    "\n",
    "    df_plot4 = df[df[\"Year\"] == 2019].groupby([\"Month\"]).mean()\n",
    "    plt.plot([i for i in range(1,4)], df_plot4[\"PM2.5\"], label = \"year 2019\")\n",
    "\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "source": [
    "### Extract date string for wind and temp"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_date_string(df):    \n",
    "    df[\"Year\"] = df[\"datetime\"].apply(lambda x: int(x[:4]))\n",
    "    df[\"Month\"] = df[\"datetime\"].apply(lambda x: int(x[5:7]))\n",
    "    df[\"Day\"] = df[\"datetime\"].apply(lambda x: int(x[8:10]))\n",
    "    df[\"UTC Hour\"] = df[\"datetime\"].apply(lambda x: int(x[11:13]))\n",
    "    return df"
   ]
  },
  {
   "source": [
    "### See wind direct trend each year"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wind_direct_trend_each_year(df):\n",
    "\n",
    "    df_plot1 = df[df[\"datetime\"] < datetime(2017,1,1,0,0,0)].groupby([\"Month\"]).mean()\n",
    "    plt.plot([i for i in range(3,13)],df_plot1[\"WindDir\"],label = \"year 2016\")\n",
    "    \n",
    "    df_plot2 = df[ (datetime(2017,1,1,0,0,0) <= df[\"datetime\"]) & \\\n",
    "       (df[\"datetime\"] < datetime(2018,1,1,0,0,0))].groupby([\"Month\"]).mean()\n",
    "    plt.plot([i for i in range(1,13)],df_plot2[\"WindDir\"],label = \"year 2017\")\n",
    "    \n",
    "    df_plot1 = df[(datetime(2018,1,1,0,0,0) <= df[\"datetime\"]) & \\\n",
    "       (df[\"datetime\"] < datetime(2019,1,1,0,0,0))].groupby([\"Month\"]).mean()\n",
    "    plt.plot([i for i in range(1,13)],df_plot1[\"WindDir\"],label = \"year 2018\")\n",
    "    \n",
    "    df_plot1 = df[  (datetime(2019,1,1,0,0,0) <= df[\"datetime\"]) & \\\n",
    "       (df[\"datetime\"] < datetime(2020,1,1,0,0,0))].groupby([\"Month\"]).mean()\n",
    "    plt.plot([i for i in range(1,4)],df_plot1[\"WindDir\"],label = \"year 2019\")\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "source": [
    "### See wind speed trend each year"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wind_speed_trend_each_year(df):\n",
    "\n",
    "    df_plot1 = df[df[\"datetime\"] < datetime(2017,1,1,0,0,0)].groupby([\"Month\"]).mean()\n",
    "    plt.plot([i for i in range(3,13)],df_plot1[\"Wind Speed(km/h)\"],label = \"year 2016\")\n",
    "    \n",
    "    df_plot2 = df[ (datetime(2017,1,1,0,0,0) <= df[\"datetime\"]) & \\\n",
    "       (df[\"datetime\"] < datetime(2018,1,1,0,0,0))].groupby([\"Month\"]).mean()\n",
    "    plt.plot([i for i in range(1,13)],df_plot2[\"Wind Speed(km/h)\"],label = \"year 2017\")\n",
    "    \n",
    "    df_plot1 = df[(datetime(2018,1,1,0,0,0) <= df[\"datetime\"]) & \\\n",
    "       (df[\"datetime\"] < datetime(2019,1,1,0,0,0))].groupby([\"Month\"]).mean()\n",
    "    plt.plot([i for i in range(1,13)],df_plot1[\"Wind Speed(km/h)\"],label = \"year 2018\")\n",
    "    \n",
    "    df_plot1 = df[  (datetime(2019,1,1,0,0,0) <= df[\"datetime\"]) & \\\n",
    "       (df[\"datetime\"] < datetime(2020,1,1,0,0,0))].groupby([\"Month\"]).mean()\n",
    "    plt.plot([i for i in range(1,4)],df_plot1[\"Wind Speed(km/h)\"],label = \"year 2019\")\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "source": [
    "### See temp trend each year"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temp_trend_each_year(df):\n",
    "\n",
    "    df_plot1 = df[df[\"datetime\"] < datetime(2017,1,1,0,0,0)].groupby([\"Month\"]).mean()\n",
    "    plt.plot([i for i in range(3,13)],df_plot1[\"Temp(C)\"],label = \"year 2016\")\n",
    "    \n",
    "    df_plot2 = df[ (datetime(2017,1,1,0,0,0) <= df[\"datetime\"]) & \\\n",
    "       (df[\"datetime\"] < datetime(2018,1,1,0,0,0))].groupby([\"Month\"]).mean()\n",
    "    plt.plot([i for i in range(1,13)],df_plot2[\"Temp(C)\"],label = \"year 2017\")\n",
    "    \n",
    "    df_plot1 = df[(datetime(2018,1,1,0,0,0) <= df[\"datetime\"]) & \\\n",
    "       (df[\"datetime\"] < datetime(2019,1,1,0,0,0))].groupby([\"Month\"]).mean()\n",
    "    plt.plot([i for i in range(1,13)],df_plot1[\"Temp(C)\"],label = \"year 2018\")\n",
    "    \n",
    "    df_plot1 = df[  (datetime(2019,1,1,0,0,0) <= df[\"datetime\"]) & \\\n",
    "       (df[\"datetime\"] < datetime(2020,1,1,0,0,0))].groupby([\"Month\"]).mean()\n",
    "    plt.plot([i for i in range(1,4)],df_plot1[\"Temp(C)\"],label = \"year 2019\")\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "source": [
    "### convert hotspot acq_time and acq_date to datetime and extract to each field"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_zero_acq_time(date):\n",
    "    \n",
    "    convert_date = str(date)\n",
    "    if len(convert_date) == 2:\n",
    "        return \"00\"+convert_date\n",
    "    elif len(convert_date) == 3:\n",
    "        return \"0\"+convert_date\n",
    "    else:\n",
    "        return convert_date\n",
    "\n",
    "def hotspot_convert_datetime(df):\n",
    "\n",
    "    df[\"acq_time_str\"] = df[\"acq_time\"].apply(lambda x: add_zero_acq_time(x))\n",
    "    \n",
    "    df[\"Year\"] = df[\"acq_date\"].apply(lambda x: int(x[:4]))\n",
    "    df[\"Month\"] = df[\"acq_date\"].apply(lambda x: int(x[5:7]))\n",
    "    df[\"Day\"] = df[\"acq_date\"].apply(lambda x: int(x[8:10]))\n",
    "    df[\"UTC Hour\"] = df[\"acq_time_str\"].apply(lambda x: int(str(x)[:-2]))\n",
    "    df[\"UTC Min\"] = df[\"acq_time_str\"].apply(lambda x: int(str(x)[-2:]))\n",
    "\n",
    "    df[\"datetime_str\"] = df[\"Year\"].astype(str)+\"-\" \\\n",
    "                            +df[\"Month\"].astype(str)+\"-\" \\\n",
    "                            +df[\"Day\"].astype(str)+\" \" \\\n",
    "                            +df[\"UTC Hour\"].astype(str)+\":\" \\\n",
    "                            +df[\"UTC Min\"].astype(str)+\":\" \\\n",
    "                            +\"00\"\n",
    "\n",
    "    df[\"datetime\"] = df[\"datetime_str\"].apply(lambda x: datetime.strptime(x, \"%Y-%m-%d %H:%M:%S\"))\n",
    "    df[\"datetime\"] = df[\"datetime\"] + timedelta(hours = 7)\n",
    "\n",
    "    df[\"datetime_str\"] = df[\"datetime\"].astype(str)\n",
    "    df[\"Year\"] = df[\"datetime_str\"].apply(lambda x: int(x[:4]))\n",
    "    df[\"Month\"] = df[\"datetime_str\"].apply(lambda x: int(x[5:7]))\n",
    "    df[\"Day\"] = df[\"datetime_str\"].apply(lambda x: int(x[8:10]))\n",
    "    df[\"UTC Hour\"] = df[\"datetime_str\"].apply(lambda x: int(str(x)[11:13]))\n",
    "    df[\"UTC Min\"] = df[\"datetime_str\"].apply(lambda x: int(str(x)[14:16]))\n",
    "    df.drop(columns = [\"datetime_str\"], inplace = True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hotspot_trend_each_year(df, feature):\n",
    "\n",
    "    df_plot1 = df[df[\"datetime\"] < datetime(2017,1,1,0,0,0)].groupby([\"Month\"]).mean()\n",
    "    plt.plot([i for i in range(3,13)],df_plot1[\"feature\"],label = \"year 2016\")\n",
    "    \n",
    "    df_plot2 = df[ (datetime(2017,1,1,0,0,0) <= df[\"datetime\"]) & \\\n",
    "       (df[\"datetime\"] < datetime(2018,1,1,0,0,0))].groupby([\"Month\"]).mean()\n",
    "    plt.plot([i for i in range(1,13)],df_plot2[\"feature\"],label = \"year 2017\")\n",
    "    \n",
    "    df_plot1 = df[(datetime(2018,1,1,0,0,0) <= df[\"datetime\"]) & \\\n",
    "       (df[\"datetime\"] < datetime(2019,1,1,0,0,0))].groupby([\"Month\"]).mean()\n",
    "    plt.plot([i for i in range(1,13)],df_plot1[\"feature\"],label = \"year 2018\")\n",
    "    \n",
    "    df_plot1 = df[  (datetime(2019,1,1,0,0,0) <= df[\"datetime\"]) & \\\n",
    "       (df[\"datetime\"] < datetime(2020,1,1,0,0,0))].groupby([\"Month\"]).mean()\n",
    "    plt.plot([i for i in range(1,4)],df_plot1[\"feature\"],label = \"year 2019\")\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  }
 ]
}